The following is a Chinese machine translation, please understandï¼š


This program first crawls the bus route name through 8684, then requests keyword search services from Gaode using the name to obtain detailed information (such as station information, coordinates, running time, etc.), and finally outputs a route map of a route on the map. There are many similar blogger tutorials online, but they are outdated and currently none can run
The test file is used to crawl the main program, and the crawled circuit names will generate data_ City.txt. I have provided a reference for Jinan, and the program comes with a check for duplicate files. It is not recommended to ignore this function. Fetching will cause duplicate data to be fixed in txt, and also! The information crawled by 8684 is not entirely accurate, please note
Attention: Whether it is the keywords crawled by the 8684 website or the URLs of Gaode, there is a possibility of updating, and it is not guaranteed to be always available. If it cannot be run, priority should be given to whether it is the above problem. The daily loss requested by Gaode personal authenticators is pitifully low. In order to obtain data from one city at a time, I asked 12 people to help me apply for keys, and at the same time, I deleted these 12 keys. I applied for keys myself and wrote them in line 111
The generated bus details are saved in the city bus route. csv, and I have provided a reference for Jinan
Finally, map. py is used to generate a path map. Similarly, it requires Gaode's key (I left my own key on it, so I should be able to run the test directly) and generate an HTTP file in the map folder (create a new folder in the root directory). I don't know why opening it is slow and requires hanging a ladder (as mentioned above, a reference file is also included)
Additionally: get_ The line (7). py file is a collection of code that includes the pyqt interface. After all, my original intention for doing this was to design the course settings, interface, and search functions very rudimentary (only supporting fuzzy search). I don't have time to do it, and I'm too lazy to handle the content that's not my responsibility. If you're interested, you can improve it yourself. The crawling part of the code is the same as before, it's just a violent integration. If you are not interested in downloading, just use test.py
